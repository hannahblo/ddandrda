% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/statistica_depth_models.R
\name{sample_from_expl_depth_model}
\alias{sample_from_expl_depth_model}
\title{Sampling form an explicitly given depth model}
\usage{
sample_from_expl_depth_model(
  context,
  modus,
  scale,
  p,
  n,
  decay_type = "exp",
  depth_function,
  quasiconcavize = FALSE,
  ...
)
}
\arguments{
\item{context}{is the underlying formal context. (Objects that are not
elements of the context will not be sampled at all.)}

\item{modus}{is the modus of the statistical model.}

\item{scale}{is a scale parameter. Concretely scale = 1/ lambda, see
above. The choice of sclae instaed of lambda as a scale parameter is only for
convenience. Higher values of scale correspond to a higher variability in the
model.}

\item{p}{is an additional power which allows for further flexibility of the
shape of the decay of the probabilities as the depth values get smaller.}

\item{n}{is the number of samples to draw.}

\item{decay_type}{is the type of the decay function, more concretely one of
"exp", "inverse" or "pearsonvii".}

\item{depth_function}{is the used epth function.}

\item{quasiconcavize}{is by default set to FALSE. If set to TRUE,
depth-values that are returned by the depth function are quasiconcavized
before the model equation (see above) is applied.}

\item{...}{further parameters (e.g., degrees of freedom for the
Pearson type VII model)}
}
\description{
'sample_from_expl_depth_model' samples a number of
objects from a formal context according to an explicitly given model where in
a first step the sampling probabilities of all objects of the context are
calculated in according to a depth-based statistical model of the form

P(X=x) = C_lambda * Gamma((lambda * (1-D^mu(x))^p)),

cf. Blocher et al. 2022, p.20, equation (1).
Here, C_lambda is a normalizing constant, mu is a given modus, lambda is a
scale parameter, Gamma is a (weakly decreasing) decay function, p is an
additional power (the parameter p was not present in Blocher et al. 2022).
}
